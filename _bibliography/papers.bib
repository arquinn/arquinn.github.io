---
---

@inproceedings {quinn16,
author = {Andrew Quinn and David Devecsery and Peter M. Chen and Jason Flinn},
title = {JetStream: Cluster-Scale Parallelization of Information Flow Queries},
abstract={Dynamic information flow tracking (DIFT) is an important
                  tool in many domains, such as security, debugging,
                  forensics, provenance, configuration
                  troubleshooting, and privacy tracking. However, the
                  usability of DIFT is currently limited by its high
                  overhead; complex information flow queries can take
                  up to two orders of magnitude longer to execute than
                  the original execution of the program. This
                  precludes interactive uses in which users
                  iteratively refine queries to narrow down bugs,
                  leaks of private data, or performance anomalies.
                  JetStream applies cluster computing to parallelize
                  and accelerate information flow queries over past
                  executions. It uses deterministic record and replay
                  to time slice executions into distinct contiguous
                  chunks of execution called epochs, and it tracks
                  information flow for each epoch on a separate core
                  in the cluster. It structures the aggregation of
                  information flow data from each epoch as a streaming
                  computation. Epochs are arranged in a sequential
                  chain from the beginning to the end of program
                  execution; relationships to program inputs (sources)
                  are streamed forward along the chain, and
                  relationships to program outputs (sinks) are
                  streamed backward. Jet- Stream is the first system
                  to parallelize DIFT across a cluster. Our results
                  show that JetStream queries scale to at least 128
                  cores over a wide range of applications. JetStream
                  accelerates DIFT queries to run 12–48 times faster
                  than sequential queries; in most cases, queries run
                  faster than the original execution of the program.},
booktitle = {12th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 16)},
year = {2016},
isbn = {978-1-931971-33-1},
address = {Savannah, GA},
pages = {451--466},
url = {https://www.usenix.org/conference/osdi16/technical-sessions/presentation/quinn},
publisher = {{USENIX} Association},
month = nov,
pdf={quinn16.pdf}
}

@inproceedings {quinn18,
author = {Andrew Quinn and Jason Flinn and Michael Cafarella},
title = {Sledgehammer: Cluster-Fueled Debugging},
abstract= { Current debugging tools force developers to choose between
                  power and interactivity. Interactive debuggers such
                  as gdb let them quickly inspect application state
                  and monitor execution, which is perfect for simple
                  bugs. However, they are not powerful enough for
                  complex bugs such as wild stores and synchronization
                  errors where developers do not know which values to
                  inspect or when to monitor the execution. So,
                  developers add logging, insert timing measurements,
                  and create functions that verify invariants. Then,
                  they re-run applications with this
                  instrumentation. These powerful tools are,
                  unfortunately, not interactive; they can take
                  minutes or hours to answer one question about a
                  complex execution, and debugging involves asking and
                  answering many such questions.  In this paper, we
                  propose cluster-fueled debugging, which provides
                  interactivity for powerful debugging tools by
                  parallelizing their work across many cores in a
                  cluster. At sufficient scale, developers can get
                  answers to even detailed queries in a few
                  seconds. Sledgehammer is a cluster-fueled debugger:
                  it improves performance by timeslicing program
                  execution, debug instrumentation, and analysis of
                  results, and then executing each chunk of work on a
                  separate core. Sledgehammer enables powerful,
                  interactive debugging tools that are infeasible
                  today. Parallel retro-logging allows developers to
                  change their logging instrumentation and then
                  quickly see what the new logging would have produced
                  on a previous execution. Continuous function
                  evaluation logically evaluates a function such as a
                  data-structure integrity check at every point in a
                  program’s execution. Retro-timing allows fast
                  performance analysis of a previous execution. With
                  1024 cores, Sledgehammer executes these tools
                  hundreds of times faster than single-core execution
                  while returning identical results.  },
booktitle = {13th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 18)},
year = {2018},
isbn = {978-1-939133-08-3},
address = {Carlsbad, CA},
pages = {545--560},
url = {https://www.usenix.org/conference/osdi18/presentation/quinn},
publisher = {{USENIX} Association},
month = oct,
pdf={quinn18.pdf}
}

@inproceedings{quinn19,
author = {Quinn, Andrew and Flinn, Jason and Cafarella, Michael},
title = {You Can't Debug What You Can't See: Expanding Observability with the OmniTable},
year = {2019},
isbn = {9781450367271},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3317550.3321428},
doi = {10.1145/3317550.3321428},
abstract = {The effectiveness of a debugging tool is fundamentally
                  limited by what program state it can observe. Yet,
                  for performance reasons, all current debugging tools
                  restrict the program state that can be observed in
                  some way. For example, tools like heap analysis
                  restrict what can be observed (i.e., only global
                  variables) and tools like core dump analysis
                  restrict when observations may be made (i.e., only
                  on program termination).  Other tools effectively
                  limit the scope of observation by requiring
                  developers to specify what and when observations
                  will be made before execution (e.g., logging) or
                  during an execution (e.g., gdb).We propose a new
                  abstraction for debugging, called an OmniTable, that
                  logically exposes unrestricted access to all program
                  state at all points in an execution to
                  developers. The OmniTable represents a program
                  execution as a database-style table. Developers
                  inspect the OmniTable using a familiar declarative
                  query language: SQL. SQL simplifies the observation
                  and analysis of large, complex execution
                  state. Iterative queries are inherently consistent
                  since they operate over the same logical
                  table.Clearly, materializing the OmniTable for even
                  a simple program is infeasible due to storage and
                  processing overheads. Thus, our prototype,
                  SteamDrill, selectively materializes only the
                  regions of the OmniTable required to answer each
                  query by using deterministic record and replay to
                  reproduce the execution and dynamic instrumentation
                  to extract needed state. By expressing debugging
                  queries with relational logic, SteamDrill leverages
                  proven optimizations such as query optimization and
                  caching.  In addition, decomposition into relational
                  logic allows a query to be executed via repeated
                  replays, each replay extracting information needed
                  by the next, which can often be more efficient than
                  extracting all information during a single
                  execution.},
booktitle = {Proceedings of the Workshop on Hot Topics in Operating Systems},
pages = {163–169},
numpages = {7},
location = {Bertinoro, Italy},
series = {HotOS '19},
pdf={quinn19.pdf}
}


@inproceedings {neal20,
author = {Ian Neal and Ben Reeves and Ben Stoler and Andrew Quinn and Youngjin Kwon and Simon Peter and Baris Kasikci},
title = {{AGAMOTTO}: How Persistent is your Persistent Memory Application?},
abstract = {Persistent Memory (PM) can be used by applications to
                  directly and quickly persist any data structure,
                  without the overhead of a file system. However,
                  writing PM applications that are simultaneously
                  correct and efficient is challenging. As a result,
                  PM applications contain correctness and performance
                  bugs. Prior work on testing PM systems has low bug
                  coverage as it relies primarily on extensive test
                  cases and developer annotations.  In this paper we
                  aim to build a system for more thoroughly testing PM
                  applications. We inform our design using a detailed
                  study of 63 bugs from popular PM projects. We
                  identify two application-independent patterns of PM
                  misuse which account for the majority of bugs in our
                  study and can be detected automatically. The
                  remaining application-specific bugs can be detected
                  using compact custom oracles provided by developers.
                  We then present AGAMOTTO, a generic and extensible
                  system for discovering misuse of persistent memory
                  in PM applications. Unlike existing tools that rely
                  on extensive test cases or annotations, AGAMOTTO
                  symbolically executes PM systems to discover
                  bugs. AGAMOTTO introduces a new symbolic memory
                  model that is able to represent whether or not PM
                  state has been made persistent. AGAMOTTO uses a
                  state space exploration algorithm, which drives
                  symbolic execution towards program locations that
                  are susceptible to persistency bugs. AGAMOTTO has so
                  far identified 84 new bugs in 5 different PM
                  applications and frameworks while incurring no false
                  positives.},
booktitle = {14th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 20)},
year = {2020},
isbn = {978-1-939133-19-9},
pages = {1047--1064},
url = {https://www.usenix.org/conference/osdi20/presentation/neal},
publisher = {{USENIX} Association},
month = nov,
pdf={neal20.pdf}
}

@inproceedings{neal21,
author = {Neal, Ian and Quinn, Andrew and Kasikci, Baris},
title = {Hippocrates: Healing Persistent Memory Bugs without Doing Any Harm},
year = {2021},
isbn = {9781450383172},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3445814.3446694},
doi = {10.1145/3445814.3446694},
abstract = {Persistent memory (PM) technologies aim to revolutionize
                  storage systems, providing persistent storage at
                  near-DRAM speeds. Alas, programming PM systems is
                  error-prone, as the misuse or omission of the
                  durability mechanisms (i.e., cache flushes and
                  memory fences) can lead to durability bugs (i.e.,
                  unflushed updates in CPU caches that violate crash
                  consistency). PM-specific testing and debugging
                  tools can help developers find these bugs, however
                  even with such tools, fixing durability bugs can be
                  challenging.  To determine the reason behind this
                  difficulty, we first study durability bugs and find
                  that although the solution to a durability bug seems
                  simple, the actual reasoning behind the fix can be
                  complicated and time-consuming. Overall, the
                  severity of these bugs coupled with the difficultly
                  of developing fixes for them motivates us to
                  consider automated approaches to fixing durability
                  bugs.  We introduce Hippocrates, a system that
                  automatically fixes durability bugs in PM
                  systems. Hippocrates automatically performs the
                  complex reasoning behind durability bug fixes,
                  relieving developers of time-consuming bug
                  fixes. Hippocrates’s fixes are guaranteed to be
                  safe, as they are guaranteed to not introduce new
                  bugs (“do no harm”). We use Hippocrates to
                  automatically fix 23 durability bugs in realworld
                  and research systems. We show that Hippocrates
                  produces fixes that are functionally equivalent to
                  developer fixes. We then show that solely using
                  Hippocrates’s fixes, we can create a PM port of
                  Redis which has performance rivaling and exceeding
                  the performance of a manually-developed PM-port of
                  Redis.},
booktitle = {Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {401–414},
numpages = {14},
keywords = {persistent memory, program repair},
location = {Virtual, USA},
series = {ASPLOS 2021},
pdf={neal21.pdf}
}


@inproceedings{zuo21,
author = {Zuo, Gefei and Ma, Jiacheng and Quinn, Andrew and Bhatotia, Pramod and Fonseca, Pedro and Kasikci, Baris},
title = {Execution Reconstruction: Harnessing Failure Reoccurrences for Failure Reproduction},
year = {2021},
isbn = {9781450383912},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3453483.3454101},
abstract = {Reproducing production failures is crucial for software
                  reliability. Alas, existing bug reproduction
                  approaches are not suitable for production systems
                  because they are not simultaneously efficient,
                  effective, and accurate. In this work, we survey
                  prior techniques and show that existing approaches
                  over-prioritize a subset of these properties, and
                  sacrifice the remaining ones. As a result, existing
                  tools do not enable the plethora of proposed failure
                  reproduction use-cases (e.g., debugging, security
                  forensics, fuzzing) for production failures.  We
                  propose Execution Reconstruction (ER), a technique
                  that strikes a better balance between efficiency,
                  effectiveness and accuracy for reproducing
                  production failures. ER uses hardware-assisted
                  control and data tracing to shepherd symbolic
                  execution and reproduce failures. ER’s key novelty
                  lies in identifying data values that are both
                  inexpensive to monitor and useful for eliding the
                  scalability limitations of symbolic execution. ER
                  harnesses failure reoccurrences by iteratively
                  performing tracing and symbolic execution, which
                  reduces runtime overhead. Whereas prior
                  production-grade techniques can only reproduce short
                  executions, ER can reproduce any reoccuring
                  failure. Thus, unlike existing tools, ER reproduces
                  fully replayable executions that can power a variety
                  of debugging and reliabilty use cases. ER incurs on
                  average 0.3\% (up to 1.1\%) runtime monitoring
                  overhead for a broad range of real-world systems,
                  making it practical for real-world deployment.},
booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
pages = {1155–1170},
numpages = {16},
pdf={zuo21.pdf}
}